{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "behind-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '../../../../'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "import pyro\n",
    "import torch\n",
    "import torchvision\n",
    "import glob\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as gnn\n",
    "import torch_geometric.transforms as gnn_T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torch_cluster import grid_cluster\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MNISTSuperpixels, CoraFull\n",
    "from torch_geometric.data import Batch, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "random-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "split-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-interpretation",
   "metadata": {},
   "source": [
    "## Setup and Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "olive-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = './MNIST/graphs/'\n",
    "\n",
    "graph_train_dataset = MNISTSuperpixels(root=dataset_folder, train=True)\n",
    "graph_test_dataset = MNISTSuperpixels(root=dataset_folder, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flexible-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = gnn_T.Compose([\n",
    "    gnn_T.Cartesian(),\n",
    "    gnn_T.ToSparseTensor(remove_edge_index=False),\n",
    "    gnn_T.ToUndirected(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-moral",
   "metadata": {},
   "source": [
    "## Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hired-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplineCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SplineCNN, self).__init__()\n",
    "        self.conv1 = gnn.SplineConv(1, 32, dim=2, kernel_size=5)\n",
    "        self.conv2 = gnn.SplineConv(32, 64, dim=2, kernel_size=5)\n",
    "        self.fc1 = torch.nn.Linear(64, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        cluster = gnn.graclus(edge_index, num_nodes=x.size(0))\n",
    "        data = Batch(x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch)\n",
    "        data = gnn.max_pool(cluster, data)\n",
    "        \n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        cluster = gnn.graclus(edge_index, num_nodes=x.size(0))\n",
    "        data = Batch(x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch)\n",
    "        data = gnn.max_pool(cluster, data)\n",
    "        \n",
    "        x, batch = data.x, data.batch\n",
    "        \n",
    "        x = gnn.global_mean_pool(x, batch)  \n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "classical-medline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplineCNN(\n",
       "  (conv1): SplineConv(1, 32, dim=2)\n",
       "  (conv2): SplineConv(32, 64, dim=2)\n",
       "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SplineCNN\n",
    "model = SplineCNN().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pending-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 0\n",
    "\n",
    "train_frac = 0.8\n",
    "train_idx = int(len(graph_train_dataset) * train_frac)\n",
    "train_split = graph_train_dataset[:train_idx]\n",
    "val_split = graph_train_dataset[train_idx:]\n",
    "\n",
    "batch_size = 16\n",
    "graph_train_loader = DataLoader(train_split, batch_size=batch_size, shuffle=False)\n",
    "graph_val_loader = DataLoader(val_split, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incomplete-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset_loader, preprocessor, device):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm.tqdm(train_dataset_loader):\n",
    "        optimizer.zero_grad()\n",
    "        batch = preprocessor(batch.to(device))\n",
    "        out = model(batch)\n",
    "        loss = F.nll_loss(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def validate_model(model, val_dataset_loader, preprocessor, device):\n",
    "    model.eval()\n",
    "    \n",
    "    val_acc = []\n",
    "    \n",
    "    for batch in val_dataset_loader:\n",
    "        batch = preprocessor(batch.to(device))\n",
    "        pred_logits = model(batch)\n",
    "        _, pred = pred_logits.max(dim=1)\n",
    "        acc = (pred.eq(batch.y).sum() / batch.y.size(0)).item()\n",
    "        val_acc.append(acc)\n",
    "    \n",
    "    return sum(val_acc) / len(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "portable-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(epochs):\n",
    "    \n",
    "#     print(f'Epoch: {epoch}')\n",
    "        \n",
    "#     train_model(model, graph_train_loader, preprocess, device)\n",
    "#     val_acc = validate_model(model, graph_val_loader, preprocess, device)\n",
    "#     train_acc = validate_model(model, graph_train_loader, preprocess, device)\n",
    "    \n",
    "#     print(f'Train Acc: {train_acc}, Val Acc: {val_acc}')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "furnished-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_test_loader = DataLoader(graph_test_dataset, batch_size=batch_size)\n",
    "# test_acc = validate_model(model, graph_test_loader, preprocess, device)\n",
    "# test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-reach",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "laughing-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, accuracy_score\n",
    "\n",
    "def train_gvae(model, train_dataset_loader, optimiser, preprocessor, device):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm.tqdm(train_dataset_loader):\n",
    "        optimiser.zero_grad()\n",
    "        batch = preprocessor(batch.to(device))\n",
    "        edge_probs, z, mean, log_std = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        loss, _, _ = model.loss_function(mean, log_std, edge_probs)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "def validate_gvae(model, val_dataset_loader, preprocessor, device):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        val_elbos = []\n",
    "        log_lik = []\n",
    "        kl_losses = []\n",
    "        average_precisions = []\n",
    "        accuracies = []\n",
    "\n",
    "        for batch in tqdm.tqdm(val_dataset_loader):\n",
    "            # Forward Pass\n",
    "            batch = preprocessor(batch.to(device))\n",
    "            edge_probs, z, mean, log_std = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            elbo, log_prob, kl_loss = model.loss_function(mean, log_std, edge_probs)\n",
    "            # Accumulate Metrics\n",
    "            val_elbos.append(elbo)\n",
    "            log_lik.append(log_prob)\n",
    "            kl_losses.append(kl_loss)\n",
    "            ones = torch.ones_like(edge_probs.cpu())\n",
    "            ap = average_precision_score(ones, edge_probs.cpu())\n",
    "            average_precisions.append(ap)\n",
    "            mask = edge_probs > 0.5\n",
    "            edge_probs[mask] = 1\n",
    "            edge_probs[~mask] = 0\n",
    "            acc = accuracy_score(ones, edge_probs.cpu())\n",
    "            accuracies.append(acc)\n",
    "            \n",
    "    total_elbo = sum(val_elbos) / len(val_elbos)\n",
    "    total_log_lik = sum(log_lik) / len(log_lik)\n",
    "    total_kl = sum(kl_losses) / len(kl_losses)\n",
    "    ap = sum(average_precisions) / len(average_precisions)\n",
    "    acc = sum(accuracies) / len(accuracies)\n",
    "    \n",
    "    return total_elbo, total_log_lik, total_kl, ap, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "maritime-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_train_dataset = CoraFull(root=dataset_folder)  # , train=True)\n",
    "graph_test_dataset = CoraFull(root=dataset_folder)  # , train=False)\n",
    "\n",
    "# graph_train_dataset = MNISTSuperpixels(root=dataset_folder, train=True)\n",
    "# graph_test_dataset = MNISTSuperpixels(root=dataset_folder, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "subjective-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 0\n",
    "\n",
    "train_frac = 0.8\n",
    "train_idx = int(len(graph_train_dataset) * train_frac)\n",
    "train_split = graph_train_dataset[:train_idx]\n",
    "val_split = graph_train_dataset[train_idx:]\n",
    "\n",
    "batch_size = 512\n",
    "graph_train_loader = DataLoader(train_split, batch_size=batch_size, shuffle=False)\n",
    "graph_val_loader = DataLoader(val_split, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "martial-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch_geometric.nn import DeepGCNLayer\n",
    "\n",
    "\n",
    "LOG_CONST = 1e-15\n",
    "\n",
    "\n",
    "class SplineConvUnit(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, edge_dim, dropout=0, latent_encoder=False):\n",
    "        super(SplineConvUnit, self).__init__()\n",
    "        self.edge_dim = edge_dim\n",
    "        self.dropout = dropout\n",
    "        self.conv = gnn.SplineConv(input_dim, output_dim, dim=edge_dim, kernel_size=5)\n",
    "        self.latent_encoder = latent_encoder\n",
    "        \n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "        x = self.conv(x, edge_index, edge_attr)\n",
    "        \n",
    "        if self.latent_encoder:\n",
    "            return x\n",
    "        \n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class GCNConvUnit(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, edge_dim, dropout=0, latent_encoder=False):\n",
    "        super(GCNConvUnit, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv = gnn.GCNConv(input_dim, output_dim)\n",
    "        self.latent_encoder = latent_encoder\n",
    "        \n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "        x = self.conv(x, edge_index)\n",
    "        \n",
    "        if self.latent_encoder:\n",
    "            return x\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class CoMAUnit(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, edge_dim, dropout=0, latent_encoder=False):\n",
    "        super(CoMAUnit, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv = gnn.GCNConv(input_dim, output_dim)\n",
    "        self.latent_encoder = latent_encoder\n",
    "        \n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "        x = self.conv(x, edge_index)\n",
    "        \n",
    "        if self.latent_encoder:\n",
    "            return x\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, conv_class, input_dim, hidden_dim1, hidden_dim2, latent_dim, edge_dim=None, dropout=0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = conv_class(input_dim, hidden_dim1, edge_dim, dropout)\n",
    "        self.conv2 = conv_class(hidden_dim1, hidden_dim2, edge_dim, dropout)\n",
    "        \n",
    "        kwargs = {\n",
    "            'input_dim': hidden_dim2,\n",
    "            'output_dim': latent_dim,\n",
    "            'edge_dim': edge_dim,\n",
    "            'latent_encoder': True,\n",
    "        }\n",
    "        \n",
    "        if conv_class == SplineConvUnit:\n",
    "            kwargs['edge_dim'] = edge_dim\n",
    "        \n",
    "        self.mean = conv_class(**kwargs)\n",
    "        self.log_std = conv_class(**kwargs)\n",
    "        self.edge_dim = edge_dim\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def get_output_dim(self):\n",
    "        return self.output_dim\n",
    "    \n",
    "    def get_edge_dim(self):\n",
    "        return self.edge_dim\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor) -> [Tensor, Tensor]:\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        mean = self.mean(x, edge_index, edge_attr)\n",
    "        log_std = self.log_std(x, edge_index, edge_attr)\n",
    "        return mean, log_std\n",
    "    \n",
    "\n",
    "class GraphVAE(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    https://github.com/AntixK/PyTorch-VAE/blob/master/models/vanilla_vae.py\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GraphVAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def encode(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor) -> [Tensor, Tensor]:\n",
    "        return self.encoder(x, edge_index, edge_attr)\n",
    "    \n",
    "    def decode(self, z: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        return self.decoder(z, edge_index)\n",
    "    \n",
    "    def reparametrise(self, mean: Tensor, log_std: Tensor) -> Tensor:\n",
    "        std = torch.exp(log_std)\n",
    "        \n",
    "        # Note: Just 1 MC particle\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mean + eps * std\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor) -> [Tensor, Tensor, Tensor, Tensor]:\n",
    "        res = self.encode(x, edge_index, edge_attr)\n",
    "        mean, log_std = self.encode(x, edge_index, edge_attr)\n",
    "        z = self.reparametrise(mean, log_std)\n",
    "        return self.decode(z, edge_index), z, mean, log_std\n",
    "\n",
    "    def generate(self, x: Tensor) -> Tensor:\n",
    "        return self.forward(x)[0]\n",
    "    \n",
    "    def loss_function(self, mean: Tensor, log_std: Tensor, pos_edge_probs: Tensor) -> Tensor:\n",
    "        pos_log_prob = -torch.log(pos_edge_probs + LOG_CONST).mean()\n",
    "        # neg_log_prob = -torch.log(1 - neg_edge_probs + LOG_CONST).mean()\n",
    "        log_prob = pos_log_prob  # + neg_log_prob\n",
    "        \n",
    "        kl_loss = torch.sum(1 + 2 * log_std - mean ** 2 - log_std.exp() ** 2, dim=1)\n",
    "        kl_loss = -0.5 * torch.mean(kl_loss)\n",
    "        \n",
    "        loss = log_prob + kl_loss\n",
    "        \n",
    "        return loss, log_prob, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "literary-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = gnn_T.Compose([\n",
    "    gnn_T.TargetIndegree()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "dominican-prayer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphVAE(\n",
       "  (encoder): Encoder(\n",
       "    (conv1): GCNConvUnit(\n",
       "      (conv): GCNConv(1, 64)\n",
       "    )\n",
       "    (conv2): GCNConvUnit(\n",
       "      (conv): GCNConv(64, 32)\n",
       "    )\n",
       "    (mean): GCNConvUnit(\n",
       "      (conv): GCNConv(32, 16)\n",
       "    )\n",
       "    (log_std): GCNConvUnit(\n",
       "      (conv): GCNConv(32, 16)\n",
       "    )\n",
       "  )\n",
       "  (decoder): InnerProductDecoder()\n",
       ")"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import InnerProductDecoder\n",
    "\n",
    "input_dim = 1\n",
    "hidden1 = 64\n",
    "hidden2 = 32\n",
    "edge_dim = 2\n",
    "latent_dim = 16\n",
    "dropout = 0.5\n",
    "\n",
    "conv_class = GCNConvUnit\n",
    "encoder = Encoder(conv_class, input_dim, hidden1, hidden2, latent_dim, edge_dim, dropout).to(device)\n",
    "decoder = InnerProductDecoder().to(device)\n",
    "gvae = GraphVAE(encoder, decoder).to(device)\n",
    "\n",
    "gvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data shape\n",
    "Batch(batch=[19793], edge_attr=[126842, 1], edge_index=[2, 126842], x=[19793, 8710], y=[19793])\n",
    "torch.Size([19793, 8710]) torch.Size([2, 126842]) torch.Size([126842, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "interim-custom",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape\n",
      "Batch(batch=[19793], edge_attr=[126842, 1], edge_index=[2, 126842], x=[19793, 8710], y=[19793])\n",
      "torch.Size([19793, 8710]) torch.Size([2, 126842]) torch.Size([126842, 1])\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-451-9be7d10626c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0medge_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-445-017bf3cea81e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparametrise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-445-017bf3cea81e>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-445-017bf3cea81e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-445-017bf3cea81e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/rrr2417/deepscm/ENV2/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "graph_trial_loader = DataLoader(graph_train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "for x in graph_trial_loader:\n",
    "    break\n",
    "\n",
    "gvae.eval()\n",
    "    \n",
    "_data = preprocess(x.to(device))\n",
    "\n",
    "print('Data shape')\n",
    "print(_data)\n",
    "print(_data.x.shape, _data.edge_index.shape, _data.edge_attr.shape)\n",
    "print()\n",
    "\n",
    "edge_probs, z, mean, log_std = gvae(_data.x, _data.edge_index, _data.edge_attr)\n",
    "print('Output shape')\n",
    "print(edge_probs.shape, z.shape, mean.shape, log_std.shape)\n",
    "print()\n",
    "\n",
    "print(gvae.loss_function(mean, log_std, edge_probs))\n",
    "# Calculate accuracy + precision etc. using 1 as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "accepted-blair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "accompanied-makeup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 75, 1]), torch.Size([3, 75]))"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x, _batch = to_dense_batch(_data.x, _data.batch)\n",
    "_x.shape, _batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "buried-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/94 [00:00<00:08, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:08<00:00, 10.95it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Val set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:06<00:00,  3.47it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:26<00:00,  3.51it/s]\n",
      "  2%|▏         | 2/94 [00:00<00:08, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Elbo: 1.6104369163513184, Val Elbo: 1.60963773727417\n",
      "Train Log Lik: 1.5065380334854126, Val Log Lik: 1.5062659978866577\n",
      "Train KL: 0.10389874875545502, Val KL: 0.1033717542886734\n",
      "Train AP: 1.0, Val AP: 1.0\n",
      "Train Acc: 0.5018537162577388, Val Acc: 0.5019539535957878\n",
      "\n",
      "Epoch: 1\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:08<00:00, 11.17it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Val set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:06<00:00,  3.69it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:26<00:00,  3.56it/s]\n",
      "  2%|▏         | 2/94 [00:00<00:08, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Elbo: 1.6102389097213745, Val Elbo: 1.609022617340088\n",
      "Train Log Lik: 1.5049399137496948, Val Log Lik: 1.50433349609375\n",
      "Train KL: 0.10529859364032745, Val KL: 0.1046890914440155\n",
      "Train AP: 1.0, Val AP: 1.0\n",
      "Train Acc: 0.5016965414825028, Val Acc: 0.5018609673086637\n",
      "\n",
      "Epoch: 2\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:08<00:00, 11.11it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Val set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:06<00:00,  3.63it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:26<00:00,  3.58it/s]\n",
      "  2%|▏         | 2/94 [00:00<00:08, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Elbo: 1.6090431213378906, Val Elbo: 1.6101363897323608\n",
      "Train Log Lik: 1.5049176216125488, Val Log Lik: 1.5067613124847412\n",
      "Train KL: 0.10412514209747314, Val KL: 0.10337506234645844\n",
      "Train AP: 1.0, Val AP: 1.0\n",
      "Train Acc: 0.501633845874357, Val Acc: 0.5016592835883632\n",
      "\n",
      "Epoch: 3\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:08<00:00, 11.00it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Val set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:06<00:00,  3.68it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:26<00:00,  3.60it/s]\n",
      "  2%|▏         | 2/94 [00:00<00:09, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Elbo: 1.6082805395126343, Val Elbo: 1.6081209182739258\n",
      "Train Log Lik: 1.5043376684188843, Val Log Lik: 1.5050033330917358\n",
      "Train KL: 0.10394272208213806, Val KL: 0.10311751067638397\n",
      "Train AP: 1.0, Val AP: 1.0\n",
      "Train Acc: 0.501660929165506, Val Acc: 0.5017431790399384\n",
      "\n",
      "Epoch: 4\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:08<00:00, 10.96it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Val set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:06<00:00,  3.67it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:26<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Elbo: 1.6086026430130005, Val Elbo: 1.6081657409667969\n",
      "Train Log Lik: 1.5013962984085083, Val Log Lik: 1.5016707181930542\n",
      "Train KL: 0.10720643401145935, Val KL: 0.10649512708187103\n",
      "Train AP: 1.0, Val AP: 1.0\n",
      "Train Acc: 0.5013872670926388, Val Acc: 0.5014801099262081\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimiser_gvae = torch.optim.Adam(gvae.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    \n",
    "    print(f'Epoch: {epoch}')\n",
    "    print('Training')\n",
    "    train_gvae(gvae, graph_train_loader, optimiser_gvae, preprocess, device)\n",
    "    print('Validation - Val set')\n",
    "    mean_val_elbo, mean_val_log_lik, mean_val_total_kl, val_ap, val_acc = validate_gvae(gvae, graph_val_loader, preprocess, device)\n",
    "    print('Validation - Train set')\n",
    "    mean_train_elbo, mean_train_log_lik, mean_train_total_kl, train_ap, train_acc = validate_gvae(gvae, graph_train_loader, preprocess, device)\n",
    "    \n",
    "    print(f'Train Elbo: {mean_train_elbo}, Val Elbo: {mean_val_elbo}')\n",
    "    print(f'Train Log Lik: {mean_train_log_lik}, Val Log Lik: {mean_val_log_lik}')\n",
    "    print(f'Train KL: {mean_train_total_kl}, Val KL: {mean_val_total_kl}')\n",
    "    print(f'Train AP: {train_ap}, Val AP: {val_ap}')\n",
    "    print(f'Train Acc: {train_acc}, Val Acc: {val_acc}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-working",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behind-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '../../../../'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "import pyro\n",
    "import torch\n",
    "import torchvision\n",
    "import glob\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as gnn\n",
    "import torch_geometric.transforms as gnn_T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torch_cluster import grid_cluster\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MNISTSuperpixels\n",
    "from torch_geometric.data import Batch, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "random-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "split-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-interpretation",
   "metadata": {},
   "source": [
    "## Setup and Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "olive-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = './MNIST/graphs/'\n",
    "\n",
    "graph_train_dataset = MNISTSuperpixels(root=dataset_folder, train=True)\n",
    "graph_test_dataset = MNISTSuperpixels(root=dataset_folder, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flexible-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = gnn_T.Compose([\n",
    "    gnn_T.Cartesian(),\n",
    "    gnn_T.ToSparseTensor(remove_edge_index=False),\n",
    "    gnn_T.ToUndirected(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-moral",
   "metadata": {},
   "source": [
    "## Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hired-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplineCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SplineCNN, self).__init__()\n",
    "        self.conv1 = gnn.SplineConv(1, 32, dim=2, kernel_size=5)\n",
    "        self.conv2 = gnn.SplineConv(32, 64, dim=2, kernel_size=5)\n",
    "        self.fc1 = torch.nn.Linear(64, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        cluster = gnn.graclus(edge_index, num_nodes=x.size(0))\n",
    "        data = Batch(x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch)\n",
    "        data = gnn.max_pool(cluster, data)\n",
    "        \n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        cluster = gnn.graclus(edge_index, num_nodes=x.size(0))\n",
    "        data = Batch(x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch)\n",
    "        data = gnn.max_pool(cluster, data)\n",
    "        \n",
    "        x, batch = data.x, data.batch\n",
    "        \n",
    "        x = gnn.global_mean_pool(x, batch)  \n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "classical-medline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplineCNN(\n",
       "  (conv1): SplineConv(1, 32, dim=2)\n",
       "  (conv2): SplineConv(32, 64, dim=2)\n",
       "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SplineCNN\n",
    "model = SplineCNN().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pending-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 0\n",
    "\n",
    "train_frac = 0.8\n",
    "train_idx = int(len(graph_train_dataset) * train_frac)\n",
    "train_split = graph_train_dataset[:train_idx]\n",
    "val_split = graph_train_dataset[train_idx:]\n",
    "\n",
    "batch_size = 64\n",
    "graph_train_loader = DataLoader(train_split, batch_size=batch_size, shuffle=False)\n",
    "graph_val_loader = DataLoader(val_split, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incomplete-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset_loader, preprocessor, device):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm.tqdm(train_dataset_loader):\n",
    "        optimizer.zero_grad()\n",
    "        batch = preprocessor(batch.to(device))\n",
    "        out = model(batch)\n",
    "        loss = F.nll_loss(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def validate_model(model, val_dataset_loader, preprocessor, device):\n",
    "    model.eval()\n",
    "    \n",
    "    val_acc = []\n",
    "    \n",
    "    for batch in val_dataset_loader:\n",
    "        batch = preprocessor(batch.to(device))\n",
    "        pred_logits = model(batch)\n",
    "        _, pred = pred_logits.max(dim=1)\n",
    "        acc = (pred.eq(batch.y).sum() / batch.y.size(0)).item()\n",
    "        val_acc.append(acc)\n",
    "    \n",
    "    return sum(val_acc) / len(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "portable-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(f'Epoch: {epoch}')\n",
    "        \n",
    "    train_model(model, graph_train_loader, preprocess, device)\n",
    "    val_acc = validate_model(model, graph_val_loader, preprocess, device)\n",
    "    train_acc = validate_model(model, graph_train_loader, preprocess, device)\n",
    "    \n",
    "    print(f'Train Acc: {train_acc}, Val Acc: {val_acc}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "furnished-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_test_loader = DataLoader(graph_test_dataset, batch_size=batch_size)\n",
    "# test_acc = validate_model(model, graph_test_loader, preprocess, device)\n",
    "# test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-reach",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "martial-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplineCNNEncoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim):\n",
    "        super(SplineCNNEncoder, self).__init__()\n",
    "        self.conv1 = gnn.SplineConv(1, 32, dim=2, kernel_size=5)\n",
    "        self.conv2 = gnn.SplineConv(32, output_dim, dim=2, kernel_size=5)\n",
    "        # self.fc = torch.nn.Linear(64, output_dim)\n",
    "        # self.fc2 = torch.nn.Linear(128, 10)\n",
    "        self.output_dim = output_dim\n",
    "    \n",
    "    def get_output_dim(self):\n",
    "        return self.output_dim\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        # cluster = gnn.graclus(edge_index, num_nodes=x.size(0))\n",
    "        # data = Batch(x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch)\n",
    "        # data = gnn.max_pool(cluster, data)\n",
    "        \n",
    "        # x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        # cluster = gnn.graclus(edge_index, num_nodes=x.size(0))\n",
    "        data = Batch(x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch)\n",
    "        # data = gnn.max_pool(cluster, data)\n",
    "        \n",
    "        # x, batch = data.x, data.batch\n",
    "        # print(x.shape)\n",
    "        \n",
    "        # x = gnn.global_mean_pool(x, batch)\n",
    "        # print(x.shape)\n",
    "        # x = F.elu(self.fc(x))\n",
    "        # print(x.shape)\n",
    "        # x = self.fc2(x)\n",
    "        \n",
    "        return data  # F.log_softmax(x, dim=1)\n",
    "    \n",
    "\n",
    "class GraphVAE(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    https://github.com/AntixK/PyTorch-VAE/blob/master/models/vanilla_vae.py\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, encoder, decoder, latent_dim):\n",
    "        super(GraphVAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.mean = gnn.SplineConv(encoder.get_output_dim(), latent_dim, dim=2, kernel_size=5)\n",
    "        self.log_std = gnn.SplineConv(encoder.get_output_dim(), latent_dim, dim=2, kernel_size=5)\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "    def encode(self, data: Batch) -> [Batch, Batch]:\n",
    "        embed = self.encoder(data)\n",
    "        \n",
    "        x, edge_index, edge_attr, batch = embed.x, embed.edge_index, embed.edge_attr, embed.batch\n",
    "        mean = self.mean(x, edge_index, edge_attr)\n",
    "        log_std = self.log_std(x, edge_index, edge_attr)\n",
    "        \n",
    "        mean_batch = Batch(x=mean, edge_index=edge_index, edge_attr=edge_attr, batch=batch)\n",
    "        log_std_batch = Batch(x=log_std, edge_index=edge_index, edge_attr=edge_attr, batch=batch)\n",
    "        \n",
    "        return mean_batch, log_std_batch\n",
    "    \n",
    "    def decode(self, z: Batch) -> Batch:\n",
    "        recon = self.decoder(z.x, z.edge_index)\n",
    "        recon_batch = Batch(x=recon, edge_index=z.edge_index, edge_attr=z.edge_attr, batch=z.batch)\n",
    "        return recon_batch\n",
    "    \n",
    "    def reparametrise(self, mean: Batch, log_std: Batch) -> Batch:\n",
    "        std = torch.exp(log_std.x)\n",
    "        \n",
    "        # Note: Just 1 MC particle\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mean.x + eps * std\n",
    "        \n",
    "        z_batch = Batch(x=z, edge_index=mean.edge_index, edge_attr=mean.edge_attr, batch=mean.batch)\n",
    "        z_batch.x = z\n",
    "        \n",
    "        return z_batch\n",
    "    \n",
    "    def forward(self, data: Batch) -> [Batch, Batch, Batch, Batch]:\n",
    "        mean, log_std = self.encode(data)\n",
    "        z = self.reparametrise(mean, log_std)\n",
    "        return self.decode(z), data, mean, log_std\n",
    "    \n",
    "    def loss_function(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dominican-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deepscm.distributions.deep import DeepIndepNormal\n",
    "from torch_geometric.nn import InnerProductDecoder\n",
    "\n",
    "output_dim = 150\n",
    "latent_dim = 10\n",
    "\n",
    "encoder = SplineCNNEncoder(output_dim).to(device)\n",
    "decoder = InnerProductDecoder().to(device)\n",
    "model = GraphVAE(encoder, decoder, latent_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "interim-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_train_loader = DataLoader(graph_train_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "for x in graph_train_loader:\n",
    "    break\n",
    "\n",
    "_data = preprocess(x.to(device))\n",
    "recon, _, mean, log_std = model(_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "buried-thong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[150], edge_attr=[2659, 2], edge_index=[2, 2659], x=[2659])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-perry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
